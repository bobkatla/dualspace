seed: 1337
run_name: cifar10_mvp
out_dir: outputs/cifar10_mvp


# data
dataset: cifar10
batch_size: 128
num_workers: 8
split: {train: 0.7, calib: 0.15, test: 0.15}


# condition encoder g(c)->e
num_classes: 10
d_c: 64

# Optional encoder-specific knobs
g:
  hidden: 256
  depth: 1
  dropout: 0.0
  norm: l2 # options: null | layernorm | l2
  mode: linear_orth
  orth_reg: 0.0          # set >0 if you want to regularize

# training
train_steps: 20000
lr: 1.0e-4
weight_decay: 0.0
p_uncond: 0.05
log_every: 100
sample_every: 2000
save_every_steps: 2000
mixed_precision: true

# diffusion
T: 200
beta_schedule: cosine
guidance_scale: 1.3
img_size: 32
channels: 3
model: unet2d_small
ema_decay: 0.999


# Ï† extractor
d_phi: 128
phi:
  backbone: resnet18


# MDN
mdn_components: 6
mdn_hidden: 256
lr_mdn: 1.0e-3
train_steps_mdn: 5000
batch_size_mdn: 512


# sampling
K: 256
alphas: [0.5, 0.7, 0.8, 0.9, 0.95]


# logging
val_every_steps: 2000

urc:
  enabled: true
  alpha: 0.9
  mode: softplus # or hinge
  weight: 0.1
  margin: 0.0
  quantile_window: 4096
  